{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMegj21UeBGrG2S7OCDYS+N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"71bT0Ued8Txc"},"outputs":[],"source":["import os\n","import shutil\n","import whisper\n","import pandas as pd\n","from pydub import AudioSegment\n","from google.colab import drive\n","import pandas as pd\n","import random\n","\n","\n","!pip install openai-whisper pydub pandas\n"]},{"cell_type":"code","source":["root_folder = '/content/drive/MyDrive/Phonetics_Lab/c' # e d f b c\n","destination_folder = '/content/drive/MyDrive/Phonetics_Lab/SWEAR9'\n","\n","# Keywords for the search\n","search_words = ['–ø–∏–∑–¥–µ—Ü', '–±–ª—è', '—Ö—É–π', '—Å—É–∫–∞', '–µ–±–∞—Ç—å', '–ø–∏–∑–¥–∞', '–±–ª—è–¥—å', '—Ö—É–π–Ω—è', '–ø–æ—Ö—É–π']   #'–±–ª—è—Ç—å', '–Ω–∞—Ö—É–π',\n","\n","if not os.path.exists(destination_folder):\n","    os.makedirs(destination_folder)\n","\n","# Function to iter every file in every folder\n","def process_folder(folder_path):\n","    for foldername, subfolders, filenames in os.walk(folder_path):\n","        for filename in filenames:\n","            if filename.endswith('.txt'):  # if file is a transcript\n","                txt_file_path = os.path.join(foldername, filename)\n","                wav_file_path = os.path.join(foldername, filename.replace('.txt', '.wav'))  # corresponding .wav file\n","\n","                # transcript reading\n","                with open(txt_file_path, 'r', encoding='utf-8') as txt_file:\n","                    transcription = txt_file.read()\n","\n","                # checking weather there is one of the keywords in a transcript\n","                if any(word in transcription for word in search_words):\n","                    # copies .wav file –∏ .txt to the folder SWEAR\n","                    shutil.copy(wav_file_path, destination_folder)\n","                    shutil.copy(txt_file_path, destination_folder)\n","\n","process_folder(root_folder)\n","\n","#No such file or directory: '/content/drive/MyDrive/Phonetics_Lab/d/b/8d746c3f-f435-423b-8ad0-56e572e77da3.wav'\n","\n","\n","folder_path = '/content/drive/MyDrive/Phonetics_Lab/SWEAR9/audio_chunks'\n","elements = os.listdir(folder_path)\n","print(f\"Total number of elements: {len(elements)}\")"],"metadata":{"id":"fxEo5OEt9j6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_transcripts_file = '/content/drive/MyDrive/Phonetics_Lab/SWEAR/audio_chunks/chunks_transcripts.txt'\n","input_audio_dir = '/content/drive/MyDrive/Phonetics_Lab/SWEAR'\n","output_audio_dir = '/content/drive/MyDrive/Phonetics_Lab/SWEAR/audio_chunks'\n","os.makedirs(output_audio_dir, exist_ok=True)\n","\n","model = whisper.load_model(\"small\")  # use \"tiny\" for faster inference\n","\n","# function to process a single audio file\n","def process_audio(audio_path, transcript_path, output_audio_dir, output_transcripts_file):\n","    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n","\n","    # audio loading using pydub\n","    audio = AudioSegment.from_wav(audio_path)\n","    duration_ms = len(audio)\n","\n","    # transcribe using Whisper\n","    result = model.transcribe(audio_path, language=\"russian\", word_timestamps=True, fp16=False)\n","\n","    with open(output_transcripts_file, 'a', encoding='utf-8') as out_f:\n","        word_idx = 0\n","        for segment in result[\"segments\"]:\n","            for word_info in segment[\"words\"]:\n","                word = word_info[\"word\"].strip()\n","                start_sec = word_info[\"start\"]\n","                end_sec = word_info[\"end\"]\n","\n","                # seconds to milliseconds\n","                start_ms = int(start_sec * 1000)\n","                end_ms = int(end_sec * 1000)\n","\n","                # clamp to audio duration boundaries\n","                start_ms = max(0, min(start_ms, duration_ms))\n","                end_ms = max(0, min(end_ms, duration_ms))\n","\n","                # extraction word audio chunk\n","                chunk_audio = audio[start_ms:end_ms]\n","\n","                # saving the chunk\n","                chunk_filename = f\"{base_name}_chunk{word_idx}.wav\"\n","                chunk_path = os.path.join(output_audio_dir, chunk_filename)\n","                chunk_audio.export(chunk_path, format=\"wav\")\n","\n","                # writing the transcript\n","                out_f.write(f\"{chunk_filename}\\t{word}\\t{start_sec:.2f}\\t{end_sec:.2f}\\n\")\n","\n","                word_idx += 1\n","\n","# going through all audio files in the folder\n","for filename in os.listdir(input_audio_dir):\n","    if filename.endswith('.wav'):\n","        base = filename[:-4]\n","        audio_path = os.path.join(input_audio_dir, filename)\n","        transcript_path = os.path.join(input_audio_dir, base + '.txt')\n","        process_audio(audio_path, transcript_path, output_audio_dir, output_transcripts_file)\n","\n","\n","txt_path = '/content/drive/MyDrive/Phonetics_Lab/SWEAR/audio_chunks/chunks_transcripts.txt'\n","csv_path = '/content/drive/MyDrive/Phonetics_Lab/SWEAR/audio_chunks/chunks_transcripts.csv'\n","\n","# open the text file\n","df = pd.read_csv(txt_path, sep='\\t', header=None, names=[\"filename\", \"text\", \"start\", \"end\"])\n","\n","# to lowercase and remove punctuation\n","df[\"text\"] = df[\"text\"].str.lower().str.translate(str.maketrans('', '', string.punctuation))\n","\n","# saving to CSV\n","df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n","\n","print(\"CSV is saved:\", csv_path)\n"],"metadata":{"id":"uIXow8Uc97Mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Settings ===\n","csv_path = \"/content/drive/MyDrive/Phonetics_Lab/SWEAR/audio_chunks/chunks_transcripts.csv\"  # path to CSV\n","audio_dir = '/content/drive/MyDrive/Phonetics_Lab/SWEAR/audio_chunks'  # folder with audio files\n","output_dir = \"/content/drive/MyDrive/Phonetics_Lab/SWEAR/balanced_dataset\"  # where to save the new dataset\n","\n","# Keywords\n","keywords = ['–ø–∏–∑–¥–µ—Ü', '–±–ª—è', '—Ö—É–π', '—Å—É–∫–∞', '–µ–±–∞—Ç—å', '–ø–∏–∑–¥–∞', '–±–ª—è–¥—å', '—Ö—É–π–Ω—è', '–ø–æ—Ö—É–π']  # '–±–ª—è—Ç—å', '–Ω–∞—Ö—É–π',\n","\n","# Create the output folder if it doesn't exist\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load the CSV file\n","df = pd.read_csv(csv_path)\n","\n","df['text'] = df['text'].fillna('').astype(str)\n","\n","# Separate audio with keywords and without\n","contains_keyword = df[df['text'].apply(lambda x: any(k in x.lower() for k in keywords))]\n","no_keyword = df.drop(contains_keyword.index)\n","\n","# Balance the dataset\n","n_target = min(len(contains_keyword), len(no_keyword))\n","balanced_df = pd.concat([\n","    contains_keyword.sample(n=n_target, random_state=42),\n","    # no_keyword.sample(n=n_target, random_state=42)\n","]).reset_index(drop=True)\n","\n","print(f'{n_target} + {n_target} = {2 * n_target} audio files will be selected.')\n","\n","# Copy files to the new folder with renaming\n","for _, row in balanced_df.iterrows():\n","    src_path = os.path.join(audio_dir, row['filename'])\n","    safe_text = row['text'].replace(' ', '_').replace('/', '_')[:40]  # prevent long/invalid filenames\n","    new_name = f\"{safe_text}_{row['filename']}\"\n","    dst_path = os.path.join(output_dir, new_name)\n","    shutil.copy(src_path, dst_path)\n","\n","print('The balanced dataset has been saved to:', output_dir)\n"],"metadata":{"id":"vtLsiQYjAoQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_path = \"/content/drive/MyDrive/Phonetics_Lab/SWEAR9/balanced_dataset\"\n","\n","swear_words = ['–ø–∏–∑–¥–µ—Ü', '–±–ª—è', '—Ö—É–π', '—Å—É–∫–∞', '–µ–±–∞—Ç—å', '–ø–∏–∑–¥–∞', '–±–ª—è–¥—å', '—Ö—É–π–Ω—è', '–ø–æ—Ö—É–π']\n","# FOR ALL WORDS WITH \"–ô\", THE SCRIPT SOMETIMES ASSIGNS LABEL 0 INSTEAD OF 1 ‚Äî NEED TO MANUALLY CHECK AND REPLACE \"–ô\" WITH THE CORRECT CHARACTER FROM THE KEYBOARD\n","keyword_set = set(keywords)\n","\n","data = []\n","\n","# iterate all files in the folder\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.wav'):  # if it's an audio file\n","        base_word = filename.split('_')[0].lower()  # word before the first underscore, converted to lowercase\n","        label = 1 if base_word in swear_words else 0\n","        data.append([filename, base_word, label])\n","\n","df = pd.DataFrame(data, columns=['filename', 'word', 'label'])\n","\n","# saved to CSV\n","csv_path = os.path.join(folder_path, 'audio_labels.csv')\n","df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n","\n","print(\"CSV saved to:\", csv_path)\n"],"metadata":{"id":"83-dei3vA9T1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STATISTICS\n","\n","def process_folder(folder_path):\n","    csv_path = os.path.join(folder_path, \"audio_labels.csv\")\n","    if not os.path.exists(csv_path):\n","        return None\n","\n","    df = pd.read_csv(csv_path)\n","    if not {'filename', 'word', 'label'}.issubset(df.columns):\n","        return None\n","\n","    total = len(df)\n","    count_1 = (df['label'] == 1).sum()\n","    count_0 = total - count_1\n","\n","    stats = {\n","        \"folder\": os.path.basename(folder_path),\n","        \"total_audio\": total,\n","        \"label_1_count\": count_1,\n","        \"label_1_percent\": round(count_1 / total * 100, 2),\n","        \"label_0_count\": count_0,\n","        \"label_0_percent\": round(count_0 / total * 100, 2),\n","    }\n","\n","    word_counts = Counter()\n","    keyword_counts = {k: 0 for k in keywords}\n","\n","    for _, row in df.iterrows():\n","        word = str(row['word']).lower().strip()\n","        label = row['label']\n","        word_counts[word] += 1\n","        if word in keyword_set and label == 1:\n","            keyword_counts[word] += 1\n","\n","    for kw in keywords:\n","        stats[f\"keyword_{kw}_count\"] = keyword_counts[kw]\n","        stats[f\"keyword_{kw}_percent\"] = round(keyword_counts[kw] / total * 100, 2)\n","\n","    # top-20 non-keyword words\n","    for k in keyword_set:\n","        word_counts.pop(k, None)\n","    top_20 = word_counts.most_common(20)\n","    for i, (word, count) in enumerate(top_20, 1):\n","        stats[f\"top_{i}_word\"] = word\n","        stats[f\"top_{i}_count\"] = count\n","        stats[f\"top_{i}_percent\"] = round(count / total * 100, 2)\n","\n","    return stats\n","\n","# statistics for all folders\n","base_dir = \"/content/drive/MyDrive/Phonetics_Lab/DATASET\"\n","all_stats = []\n","for folder in os.listdir(base_dir):\n","    full_path = os.path.join(base_dir, folder)\n","    if os.path.isdir(full_path):\n","        stat = process_folder(full_path)\n","        if stat:\n","            all_stats.append(stat)\n","\n","# Print the results\n","df_stats = pd.DataFrame(all_stats)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', 200)\n","print(df_stats)\n"],"metadata":{"id":"5XOmQ5JNETA2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VISUALISATION OF STATISTICS\n","\n","# 1. Total number of audio files per folder\n","plt.figure(figsize=(10, 5))\n","plt.bar(df_stats[\"folder\"], df_stats[\"total_audio\"])\n","plt.title(\"Total Number of Audio Files per Folder\")\n","plt.ylabel(\"Number of Audio Files\")\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()\n","\n","# 2. Count and percentage of label == 1\n","fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n","ax[0].bar(df_stats[\"folder\"], df_stats[\"label_1_count\"], color='orange')\n","ax[0].set_title(\"Count of label == 1\")\n","ax[0].set_ylabel(\"Count\")\n","ax[1].bar(df_stats[\"folder\"], df_stats[\"label_1_percent\"], color='red')\n","ax[1].set_title(\"Percentage of label == 1\")\n","ax[1].set_ylabel(\"%\")\n","for a in ax:\n","    a.set_xticks(range(len(df_stats[\"folder\"])))\n","    a.set_xticklabels(df_stats[\"folder\"], rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()\n","\n","# 3. Bar chart for each keyword (aggregated across all folders)\n","keywords = ['–ø–∏–∑–¥–µ—Ü', '–±–ª—è', '—Ö—É–π', '—Å—É–∫–∞', '–µ–±–∞—Ç—å', '–ø–∏–∑–¥–∞', '—Ö—É–π–Ω—è', '–±–ª—è—Ç—å', '–Ω–∞—Ö—É–π', '–ø–æ—Ö—É–π']  # '–±–ª—è–¥—å'\n","total_audio = df_stats[\"total_audio\"].sum()\n","keyword_sums = {\n","    kw: df_stats[f\"keyword_{kw}_count\"].sum()\n","    for kw in keywords\n","}\n","\n","plt.figure(figsize=(12, 6))\n","plt.bar(keyword_sums.keys(), keyword_sums.values(), color='purple')\n","plt.title(\"Total Count of Keywords (label == 1) Across All Folders\")\n","plt.ylabel(\"Frequency\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n","\n","# 4. Top-10 most frequent non-keyword words across all folders\n","word_counts = {}\n","for i in range(1, 21):\n","    word_col = f\"top_{i}_word\"\n","    count_col = f\"top_{i}_count\"\n","    for _, row in df_stats.iterrows():\n","        word = row.get(word_col)\n","        count = row.get(count_col, 0)\n","        if pd.notna(word):\n","            word_counts[word] = word_counts.get(word, 0) + count\n","\n","top10 = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n","words, counts = zip(*top10)\n","\n","plt.figure(figsize=(10, 5))\n","plt.bar(words, counts, color='green')\n","plt.title(\"Top-10 Most Frequent Non-Keyword Words\")\n","plt.ylabel(\"Frequency\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"054GuHQsEpCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#CREATING 2 FOLDERS FOR LABEL 1 AND FOR LABEL 0\n","\n","# new directories\n","label_1_dir = os.path.join(base_dir, \"label_1\")\n","label_0_dir = os.path.join(base_dir, \"label_0\")\n","os.makedirs(label_1_dir, exist_ok=True)\n","os.makedirs(label_0_dir, exist_ok=True)\n","\n","rows_1 = []\n","rows_0 = []\n","\n","audio_exts = ['.wav']\n","\n","for folder in os.listdir(base_dir):\n","    folder_path = os.path.join(base_dir, folder)\n","    csv_path = os.path.join(folder_path, \"audio_labels.csv\")\n","\n","    if os.path.isdir(folder_path) and os.path.exists(csv_path):\n","        df = pd.read_csv(csv_path)\n","\n","        for _, row in df.iterrows():\n","            fname = str(row['filename'])\n","            label = row['label']\n","            word = row['word']\n","            # search for file with extension\n","            found = False\n","            for ext in audio_exts:\n","                src_path = os.path.join(folder_path, fname)\n","                if not fname.lower().endswith(ext):\n","                    src_path_full = src_path + ext\n","                else:\n","                    src_path_full = src_path\n","\n","                if os.path.exists(src_path_full):\n","                    dst_folder = label_1_dir if label == 1 else label_0_dir\n","                    dst_path = os.path.join(dst_folder, os.path.basename(src_path_full))\n","                    shutil.copy2(src_path_full, dst_path)\n","\n","                    new_row = {\n","                        \"filename\": os.path.basename(dst_path),\n","                        \"word\": word,\n","                        \"label\": label\n","                    }\n","                    if label == 1:\n","                        rows_1.append(new_row)\n","                    else:\n","                        rows_0.append(new_row)\n","                    found = True\n","                    break\n","\n","            if not found:\n","                print(f\"File not found: {fname} (in folder {folder})\")\n","\n","# save the new CSVs\n","pd.DataFrame(rows_1).to_csv(os.path.join(label_1_dir, \"audio_labels.csv\"), index=False)\n","pd.DataFrame(rows_0).to_csv(os.path.join(label_0_dir, \"audio_labels.csv\"), index=False)\n","\n","print(\"Audio files and CSVs have been separated into folders.\")\n"],"metadata":{"id":"TQuPK9Q4F6ok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_dir = \"/content/drive/MyDrive/Phonetics_Lab/DATASET\"\n","folders = [\"label_1\", \"label_0\"]\n","\n","for folder in folders:\n","    folder_path = os.path.join(base_dir, folder)\n","    csv_path = os.path.join(folder_path, \"audio_labels.csv\")\n","\n","    # Count audio files (all files except .csv)\n","    audio_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and not f.endswith('.csv')]\n","    audio_count = len(audio_files)\n","\n","    # Count rows in CSV\n","    if os.path.exists(csv_path):\n","        df = pd.read_csv(csv_path)\n","        csv_count = len(df)\n","    else:\n","        csv_count = 0\n","\n","    print(f\"{folder}: {audio_count} audio files, {csv_count} rows in CSV\")\n"],"metadata":{"id":"lIxv39W7NkyC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# REMOVING DUPLICATES IN CSV\n","\n","folder_path = \"/content/drive/MyDrive/Phonetics_Lab/DATASET/label_0\"\n","csv_path = os.path.join(folder_path, \"audio_labels.csv\")\n","\n","# Load CSV\n","df = pd.read_csv(csv_path)\n","valid_filenames = set(df['filename'].astype(str))\n","\n","# List all files in the folder\n","all_files = os.listdir(folder_path)\n","audio_exts = ['.wav']\n","\n","# Filter audio files and delete the extra ones\n","deleted_count = 0\n","\n","for file in all_files:\n","    if any(file.endswith(ext) for ext in audio_exts):\n","        if file not in valid_filenames:\n","            try:\n","                os.remove(os.path.join(folder_path, file))\n","                print(f\"üóëÔ∏è Deleted: {file}\")\n","                deleted_count += 1\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Failed to delete {file}: {e}\")\n","\n","print(f\"\\n‚úÖ Total deleted: {deleted_count} extra audio files.\")\n"],"metadata":{"id":"CcUpO6RWODqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keyword statistics\n","\n","\n","keywords = ['–ø–∏–∑–¥–µ—Ü', '–±–ª—è', '—Ö—É–π', '—Å—É–∫–∞', '–µ–±–∞—Ç—å', '–ø–∏–∑–¥–∞', '–±–ª—è–¥—å', '—Ö—É–π–Ω—è', '–±–ª—è—Ç—å', '–Ω–∞—Ö—É–π', '–ø–æ—Ö—É–π']\n","keyword_set = set(keywords)\n","\n","# Path to the file\n","csv_path = \"/content/drive/MyDrive/Phonetics_Lab/DATASET/label_1/audio_labels.csv\"\n","\n","# Read the CSV\n","df = pd.read_csv(csv_path)\n","\n","# Filter rows where label == 1\n","df_label_1 = df[df['label'] == 1]\n","\n","# Convert to lowercase and remove surrounding spaces\n","df_label_1['word'] = df_label_1['word'].astype(str).str.strip().str.lower()\n","\n","# Count all words\n","word_counts = df_label_1['word'].value_counts()\n","\n","# Split into keywords and others\n","keyword_stats = word_counts[word_counts.index.isin(keyword_set)]\n","other_stats = word_counts[~word_counts.index.isin(keyword_set)]\n","\n","print(\"Keyword statistics:\")\n","print(keyword_stats.sort_values(ascending=False))\n","\n","print(\"\\n Other words found among label==1:\")\n","print(other_stats.sort_values(ascending=False))\n"],"metadata":{"id":"-5qMnQXfOKlw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CHECK IF THERE ARE ANY KEYWORDS AMONG LABEL 0\n","\n","# Path to the CSV with label 0\n","csv_path = \"/content/drive/MyDrive/Phonetics_Lab/DATASET/label_0/audio_labels.csv\"\n","\n","# Load and preprocess\n","df = pd.read_csv(csv_path)\n","df['word'] = df['word'].astype(str).str.strip().str.lower()\n","\n","# Count keywords among label == 0\n","keyword_counts = df['word'].value_counts()\n","keyword_in_zeros = keyword_counts[keyword_counts.index.isin(keyword_set)]\n","\n","if keyword_in_zeros.empty:\n","    print(\"No keywords found among files with label == 0.\")\n","else:\n","    print(\"Keywords detected among label == 0:\")\n","    print(keyword_in_zeros.sort_values(ascending=False))\n","\n","# Read the CSV\n","df = pd.read_csv(csv_path)\n","df['word'] = df['word'].astype(str).str.strip().str.lower()\n","\n","# Mask rows with keywords\n","mask = df['word'].isin(keywords)\n","to_delete = df[mask]\n","\n","# Delete corresponding audio files\n","for fname in to_delete['filename']:\n","    file_path = os.path.join(folder_path, fname)\n","    if os.path.exists(file_path):\n","        os.remove(file_path)\n","        print(f\"Deleted file: {file_path}\")\n","    else:\n","        print(f\"‚ö†Ô∏è File not found: {file_path}\")\n","\n","# Update the CSV\n","df_clean = df[~mask]\n","df_clean.to_csv(csv_path, index=False)\n","print(f\"Removed {len(to_delete)} rows from the CSV.\")\n"],"metadata":{"id":"XuQ1JsuROokn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# KEEP A MAXIMUM OF 600 OCCURRENCES\n","\n","# Folder with label_1\n","folder_path = \"/content/drive/MyDrive/Phonetics_Lab/DATASET/label_1\"\n","csv_path = os.path.join(folder_path, \"audio_labels.csv\")\n","\n","# Load and filter\n","df = pd.read_csv(csv_path)\n","df['word'] = df['word'].astype(str).str.strip().str.lower()\n","\n","# All rows with the word \"–±–ª—è—Ç—å\"\n","bword_df = df[df['word'] == '–±–ª—è—Ç—å']\n","\n","# Keep a random sample of 600\n","keep_bword = bword_df.sample(n=600, random_state=42)\n","\n","# Rows to delete\n","drop_bword = bword_df[~bword_df['filename'].isin(keep_bword['filename'])]\n","\n","# Delete corresponding audio files\n","for fname in drop_bword['filename']:\n","    fpath = os.path.join(folder_path, fname)\n","    if os.path.exists(fpath):\n","        os.remove(fpath)\n","        print(f\"Deleted file: {fpath}\")\n","    else:\n","        print(f\"File not found: {fpath}\")\n","\n","# Update the CSV\n","df_new = df[~((df['word'] == '–±–ª—è—Ç—å') & (~df['filename'].isin(keep_bword['filename'])))]\n","df_new.to_csv(csv_path, index=False)\n","\n","print(f\"Kept 600 audio files with the word '–±–ª—è—Ç—å'. Deleted {len(drop_bword)} rows and files.\")\n"],"metadata":{"id":"fSRyBxpKOrL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AUGMENTATION\n","\n","import torchaudio\n","import torchaudio.transforms as T\n","import torch\n","from pathlib import Path\n","\n","csv_path = Path(\"/content/drive/MyDrive/Phonetics_Lab/DATASET/label_1/audio_labels.csv\")\n","audio_folder = Path(\"/content/drive/MyDrive/Phonetics_Lab/DATASET/label_1\")\n","base_folder = audio_folder\n","aug_folder = base_folder / \"augmented\"\n","aug_folder.mkdir(exist_ok=True)\n","\n","target_sr = 16000\n","target_count = 458\n","\n","# Keywords\n","keywords = ['–ø–æ—Ö—É–π']  # can be extended\n","df = pd.read_csv(csv_path)\n","df['word'] = df['word'].astype(str).str.strip().str.lower()\n","\n","# Only label == 1 samples with keywords\n","df_key = df[(df['label'] == 1) & (df['word'].isin(keywords))].copy()\n","\n","# Augmentations: noise\n","def augment_waveform(waveform, sr):\n","    transforms = [\n","        T.Vol(gain=0.02),  # noise/amplification\n","        T.PitchShift(sample_rate=sr, n_steps=2),\n","    ]\n","    augmented = [transform(waveform) for transform in transforms]\n","    return augmented\n","\n","# Generate augmentations\n","augmented_rows = []\n","generated_count = 0\n","\n","for kw in keywords:\n","    df_kw = df_key[df_key['word'] == kw]\n","    count = len(df_kw)\n","\n","    if count >= target_count:\n","        continue  # nothing to do\n","\n","    needed = target_count - count\n","    print(f\"üîÅ Augmenting '{kw}': {count} ‚Üí {target_count} (need to add {needed})\")\n","\n","    samples = df_kw.sample(n=needed, replace=True, random_state=42)\n","\n","    for _, row in samples.iterrows():\n","        old_name = row['filename']\n","        word = row['word']\n","        src_path = audio_folder / old_name\n","\n","        if not src_path.exists():\n","            print(f\"‚ö†Ô∏è File not found: {src_path}\")\n","            continue\n","\n","        try:\n","            waveform, sr = torchaudio.load(str(src_path))\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Error loading {src_path}: {e}\")\n","            continue\n","\n","        for aug_wav in augment_waveform(waveform, sr):\n","            new_name = f\"aug_{old_name}\"\n","            new_path = aug_folder / new_name\n","\n","            if new_path.exists():\n","                continue  # skip already existing file\n","\n","            torchaudio.save(str(new_path), aug_wav, sr)\n","\n","            augmented_rows.append({\n","                \"filename\": new_name,\n","                \"word\": word,\n","                \"label\": 1\n","            })\n","\n","            generated_count += 1\n","            print(f\"‚úÖ Generated: {generated_count}/{needed}\")\n","            break  # only one variant per iteration\n","\n","print(f\"\\n Total new audio files created: {generated_count}\")\n","\n","# Save new CSV\n","df_aug = pd.DataFrame(augmented_rows)\n","df_aug.to_csv(aug_folder / \"audio_labels.csv\", index=False)\n","print(f\"Saved {len(augmented_rows)} new samples to {aug_folder}\")\n"],"metadata":{"id":"F9qgUjsHPoL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FILTERING LABEL 0 AUDIOS CONTAINING BANNED WORDS\n","\n","# the path to the root folder containing subfolders with audio and CSV files\n","root_dir = \"/content/drive/MyDrive/Phonetics_Lab/SWEAR\"\n","output_dir = '/content/drive/MyDrive/Phonetics_Lab/DATASET/selected_audio'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# list of banned words (used for filtering)\n","banned_words = {'—è', '–Ω–∞', '–Ω–µ', '–≤', '—ç—Ç–æ', '–∫', '–∞', '–º–µ–Ω—è', '—Ç–∞–∫', '—Ç—ã',\n","                '–ø–∏–∑–¥–µ—Ü', '–±–ª—è', '—Ö—É–π', '—Å—É–∫–∞', '–µ–±–∞—Ç—å', '–ø–∏–∑–¥–∞', '–±–ª—è–¥—å',\n","                '—Ö—É–π–Ω—è', '–±–ª—è—Ç—å', '–Ω–∞—Ö—É–π', '–ø–æ—Ö—É–π'}\n","\n","selected = []\n","\n","# scan folders for CSV and corresponding audio files\n","#    and filter out rows containing banned words\n","for dirpath, _, filenames in os.walk(root_dir):\n","    for filename in filenames:\n","        if filename.endswith('.csv'):\n","            csv_path = os.path.join(dirpath, filename)\n","            with open(csv_path, newline='', encoding='utf-8') as f:\n","                reader = csv.reader(f)\n","                for row in reader:\n","                    if len(row) < 2:\n","                        continue\n","                    audio_filename = row[0].strip()\n","                    word = row[1].strip().lower()\n","                    if word in banned_words:\n","                        continue  # skip audio with banned words\n","                    audio_path = os.path.join(dirpath, audio_filename)\n","                    if os.path.isfile(audio_path):\n","                        selected.append((audio_path, word))\n","\n","# shuffle and keep up to 1200 clean samples\n","random.shuffle(selected)\n","selected = selected[:1200]\n","\n","# selected audio to the output folder with renamed filenames\n","for src_path, word in selected:\n","    base = os.path.basename(src_path)\n","    new_name = f\"{word}_{base}\"\n","    dest_path = os.path.join(output_dir, new_name)\n","    shutil.copy2(src_path, dest_path)\n","\n","print(f\"Copied {len(selected)} clean audio files to {output_dir}\")\n","\n","src_dir = '/content/drive/MyDrive/Phonetics_Lab/DATASET/selected_audio'\n","dst_dir = '/content/drive/MyDrive/Phonetics_Lab/DATASET/label_0'\n","\n","# create the destination folder if it doesn't exist\n","os.makedirs(dst_dir, exist_ok=True)\n","\n","# move all files from source to destination\n","for filename in os.listdir(src_dir):\n","    src_path = os.path.join(src_dir, filename)\n","    dst_path = os.path.join(dst_dir, filename)\n","    if os.path.isfile(src_path):\n","        shutil.move(src_path, dst_path)\n","\n","print(f\"All files have been moved from {src_dir} to {dst_dir}\")\n","\n"],"metadata":{"id":"JoyFKJMwQAEG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"yCWUpSzf9zvx"}}]}